{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/meps15/test.model\n",
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/python/util/dispatch.py:1096: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from itertools import product\n",
    "import itertools\n",
    "import tensorflow.compat.v1 as tf \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import sys, os\n",
    "sys.path.append(\"../\")\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tensorflow.python.platform import flags\n",
    "from scipy.optimize import basinhopping\n",
    "import time\n",
    "from adf_model.tutorial_models import dnn\n",
    "from adf_utils.utils_tf import model_prediction, model_argmax , layer_out\n",
    "from adf_tutorial.utils import cluster, gradient_graph\n",
    "#from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import experiments\n",
    "from preprocessing import pre_census\n",
    "from preprocessing import pre_compas\n",
    "from preprocessing import pre_default\n",
    "from preprocessing import pre_heart\n",
    "from preprocessing import pre_diabetes\n",
    "from preprocessing import pre_students\n",
    "from preprocessing import pre_credit\n",
    "from preprocessing import pre_bank\n",
    "from preprocessing import pre_meps15\n",
    "# from preprocessing import pre_german_credit\n",
    "# from preprocessing import pre_bank_marketing\n",
    "from tensorflow import keras\n",
    "from EIDIG import individual_discrimination_generation\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import generation_utilities\n",
    "import time\n",
    "import ADF\n",
    "import EIDIG\n",
    "\n",
    "dataset={'census':pre_census,'compas':pre_compas,'bank':pre_bank,'heart':pre_heart,'default':pre_default,\n",
    "        'credit':pre_credit,'students':pre_students,'diabetes':pre_diabetes,'meps15':pre_meps15}\n",
    "data_set='meps15'\n",
    "for sens in dataset[data_set].protected_attribs:\n",
    "    sens_attr=[sens]\n",
    "    RQ2=[]\n",
    "    for trail in range(1):\n",
    "        X=dataset[data_set].X\n",
    "        Y=dataset[data_set].y\n",
    "        input_shape=dataset[data_set].input_shape\n",
    "        nb_classes = 2\n",
    "        tf.set_random_seed(1234)\n",
    "\n",
    "        config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "        config.allow_soft_placement= True\n",
    "\n",
    "        sess = tf.Session(config=config)\n",
    "        z = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n",
    "        model = dnn(input_shape, nb_classes)   \n",
    "\n",
    "        preds = model(z)\n",
    "        saver = tf.train.Saver()\n",
    "        model_path='../models/'\n",
    "        model_path = model_path + data_set + \"/test.model\"\n",
    "        saver.restore(sess, model_path)\n",
    "\n",
    "        # construct the gradient graph\n",
    "        grad_0 = gradient_graph(z, preds)\n",
    "        num_experiment_round = 1 # the number of experiment rounds\n",
    "        g_num = 2000 # the number of seeds used in the global generation phase\n",
    "        l_num = 1000 # the maximum search iteration in the local generation phase\n",
    "        benchmark='C-a'\n",
    "        protected_attribs=sens_attr\n",
    "        input(protected_attribs)\n",
    "        # experiments.comparison(ROUND, benchmark, pre_census_income.X_train, protected_attribs, pre_census_income.constraint, adult_model, g_num, l_num)\n",
    "        constraint=dataset[data_set].constraint\n",
    "        start_time=time.time()\n",
    "        decay=0.5\n",
    "        c_num=4\n",
    "        max_iter=10\n",
    "        s_g=1.0\n",
    "        s_l=1.0\n",
    "        epsilon_l=1e-6\n",
    "        fashion='RoundRobin'\n",
    "        num_ids = np.array([0] * 3)\n",
    "        time_cost = np.array([0] * 3)\n",
    "        print(data_set,protected_attribs)\n",
    "        for i in range(num_experiment_round):\n",
    "            round_now = i + 1\n",
    "            print('--- ROUND', round_now, '---')\n",
    "            if g_num >= len(X):\n",
    "                seeds = X.copy()\n",
    "            else:\n",
    "                clustered_data = generation_utilities.clustering(X, c_num)\n",
    "                seeds = np.empty(shape=(0, len(X[0])))\n",
    "                for i in range(g_num):\n",
    "                    new_seed = generation_utilities.get_seed(clustered_data, len(X), c_num, i%c_num, fashion=fashion)\n",
    "                    seeds = np.append(seeds, [new_seed], axis=0)\n",
    "\n",
    "\n",
    "            t1 = time.time()\n",
    "            ids_EIDIG_INF, gen_EIDIG_INF, total_iter_EIDIG_INF, tot_g,g_disc,tot_l,l_disc,t_f_g = EIDIG.individual_discrimination_generation(start_time,sess,preds,z,grad_0,X, seeds, protected_attribs, constraint, model, decay, l_num, l_num+1, max_iter, s_g, s_l, epsilon_l)\n",
    "            np.save('../results/' + data_set + '/_ids_EIDIG_INF_' + str(trail) + '.npy', ids_EIDIG_INF)\n",
    "            t2 = time.time()\n",
    "            print('EIDIG-INF:', 'In', total_iter_EIDIG_INF, 'search iterations', len(gen_EIDIG_INF), 'non-duplicate instances are explored', len(ids_EIDIG_INF), 'of which are discriminatory. Time cost:', t2-t1, 's.')\n",
    "            num_ids[2] += len(ids_EIDIG_INF)\n",
    "            time_cost[2] += t2-t1\n",
    "            \n",
    "            ccc=ids_EIDIG_INF\n",
    "            print(len(ids_EIDIG_INF))\n",
    "            print('global',tot_g,g_disc)\n",
    "            RQ2.append([len(gen_EIDIG_INF)]+[len(ids_EIDIG_INF)]+[l_disc]+[tot_l]+[t_f_g])\n",
    "            if not os.path.exists('../results/'):\n",
    "                os.makedirs('../results/')\n",
    "            if not os.path.exists('../results/' + data_set + '/'):\n",
    "                os.makedirs('../results/' + data_set + '/')\n",
    "            np.save('../results/' + data_set + '/EIDIG_sens_'+str(protected_attribs[0])+'_'+str(trail)+'.npy',RQ2)\n",
    "            print('local',tot_l,l_disc)\n",
    "            print('time first',t_f_g)\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
