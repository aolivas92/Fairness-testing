{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import tensorflow.compat.v1 as tf \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "from tensorflow.python.platform import flags\n",
    "from adf_data.census import census_data\n",
    "from adf_data.bank import bank_data\n",
    "from adf_data.credit import credit_data\n",
    "from adf_data.compas import compas_data\n",
    "from adf_data.default import default_data\n",
    "from adf_data.heart import heart_data\n",
    "from adf_utils.utils_tf import model_train, model_eval\n",
    "from adf_model.tutorial_models import dnn\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def training(dataset, model_path, nb_epochs, batch_size,learning_rate):\n",
    "    \"\"\"\n",
    "    Train the model\n",
    "    :param dataset: the name of testing dataset\n",
    "    :param model_path: the path to save trained model\n",
    "    \"\"\"\n",
    "    data = {\"census\":census_data, \"credit\":credit_data, \"bank\":bank_data, \"compas\":compas_data,\n",
    "            \"default\":default_data, \"heart\":heart_data}\n",
    "    # prepare the data and model\n",
    "    X, Y, input_shape, nb_classes = data[dataset]()\n",
    "    tf.set_random_seed(1234)\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "    sess = tf.Session(config=config)\n",
    "    x = tf.placeholder(tf.float32, shape=input_shape)\n",
    "    y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n",
    "    model = dnn(input_shape, nb_classes)\n",
    "    preds = model(x)\n",
    "\n",
    "    # training parameters\n",
    "    train_params = {\n",
    "        'nb_epochs': nb_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'train_dir': model_path + dataset + \"/\",\n",
    "        'filename': 'test.model'\n",
    "    }\n",
    "\n",
    "    # training procedure\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    rng = np.random.RandomState([2019, 7, 15])\n",
    "    model_train(sess, x, y, preds, X, Y, args=train_params,\n",
    "                rng=rng, save=True)\n",
    "\n",
    "    # evaluate the accuracy of trained model\n",
    "    eval_params = {'batch_size': 128}\n",
    "    accuracy = model_eval(sess, x, y, preds, X, Y, args=eval_params)\n",
    "    print('Test accuracy on legitimate test examples: {0}'.format(accuracy))\n",
    "\n",
    "def main(argv=None):\n",
    "    training(dataset = FLAGS.dataset,\n",
    "             model_path = FLAGS.model_path,\n",
    "             nb_epochs=FLAGS.nb_epochs,\n",
    "             batch_size=FLAGS.batch_size,\n",
    "             learning_rate=FLAGS.learning_rate)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    flags.DEFINE_string(\"dataset\", \"default\", \"the name of dataset\")\n",
    "    flags.DEFINE_string(\"model_path\", \"../models/\", \"the name of path for saving model\")\n",
    "    flags.DEFINE_integer('nb_epochs', 1000, 'Number of epochs to train model')\n",
    "    flags.DEFINE_integer('batch_size', 128, 'Size of training batches')\n",
    "    flags.DEFINE_float('learning_rate', 0.01, 'Learning rate for training')\n",
    "\n",
    "    tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
