{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from itertools import product, combinations\n",
    "import tensorflow.compat.v1 as tf \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tensorflow.python.platform import flags\n",
    "import time\n",
    "from adf_data.census import census_data\n",
    "from adf_data.credit import credit_data\n",
    "from adf_data.compas import compas_data\n",
    "from adf_data.default import default_data\n",
    "from adf_data.bank import bank_data\n",
    "from adf_data.heart import heart_data\n",
    "from adf_model.tutorial_models import dnn\n",
    "from adf_utils.utils_tf import model_prediction, model_argmax , layer_out\n",
    "from adf_utils.config import census, credit, bank, compas, default, heart\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "       \n",
    "def m_instance( sample, sens_params, conf):\n",
    "    index = []\n",
    "    m_sample = []\n",
    "    for sens in sens_params:\n",
    "        index.append([i for i in range(conf.input_bounds[sens-1][0], conf.input_bounds[sens-1][1]+1)])\n",
    "      \n",
    "    for ind in list(product(*index)):     \n",
    "        temp = sample.copy()\n",
    "        for i in range(len(sens_params)):\n",
    "            temp[0][sens_params[i]-1] = ind[i]\n",
    "        m_sample.append(temp)\n",
    "    return np.array(m_sample)\n",
    "    \n",
    "def clustering(probs,m_sample, sens_params):\n",
    "    epsillon=0.025\n",
    "    cluster_dic = {}\n",
    "    cluster_dic['Seed']=m_sample[0][0]\n",
    "\n",
    "        #  to avoid k = Max + 1 \n",
    "    for i in range(len(probs)):\n",
    "\n",
    "    \n",
    "        if probs[i] == 1.0:\n",
    "            if (int( probs[i] / epsillon ) -1) not in cluster_dic.keys():\n",
    "             \n",
    "                cluster_dic[ (int( probs[i] / epsillon ) -1)] = [ [m_sample[i][0][j-1] for j in sens_params]]\n",
    "           \n",
    "            else:\n",
    "                cluster_dic[ (int( probs[i] / epsillon ) -1)].append( [m_sample[i][0][j-1] for j in sens_params] )\n",
    "\n",
    "                       \n",
    "        elif int( probs[i] / epsillon ) not in cluster_dic.keys():\n",
    "                cluster_dic[ int( probs[i] / epsillon )] = [ [m_sample[i][0][j-1] for j in sens_params] ]\n",
    "           \n",
    "        else:\n",
    "                cluster_dic[ int( probs[i] / epsillon)].append( [m_sample[i][0][j-1] for j in sens_params] )\n",
    "\n",
    "    return cluster_dic  \n",
    "\n",
    "    \n",
    "def pred_prob(sess, x, preds, m_sample, input_shape):\n",
    "        #global probs\n",
    "        probs = model_prediction(sess, x, preds, np.array(m_sample).reshape(len(m_sample),\n",
    "                                                                            input_shape[1]))[:,1:2].reshape(len(m_sample))\n",
    "        return probs        \n",
    "        \n",
    "def neuron_locator(sess, model, samples, layer_number,model_path, input_shape, nb_classes, dataset, sens_params, update_list,X,Y ):\n",
    "        if  sess._closed:\n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "            sess = tf.Session(config = config)\n",
    "            x = tf.placeholder(tf.float32, shape = input_shape)\n",
    "            y = tf.placeholder(tf.float32, shape = (None, nb_classes))\n",
    "            model = dnn(input_shape, nb_classes)   \n",
    "\n",
    "            preds = model(x)\n",
    "            saver = tf.train.Saver()\n",
    "            #model_path = model_path + dataset + \"/test.model\"\n",
    "            saver.restore(sess, model_path)\n",
    "        num_layers=len(model.layers)\n",
    "        #print(update_list[0])\n",
    "        feed_dic = {}\n",
    "        for neuron in range(len(update_list)):\n",
    "            time1 = time.time()              \n",
    "            for layer in range(0,num_layers - 1,2):\n",
    "                if layer == 0:\n",
    "                    l = model.layers[layer].fprop(samples.astype('float32'))\n",
    "                else:\n",
    "                    l = model.layers[layer].fprop(r)                   \n",
    "                if layer + 1 == (layer_number * 2) - 1:\n",
    "                    indices = []\n",
    "                    for instance in range(l.shape[0]):                       \n",
    "                        indices.append([ instance, 0, neuron])       \n",
    "                    updates = [ update_list[ neuron ] ] * l.shape[0]\n",
    "                    #print('update',update_list[ neuron ])\n",
    "                    r = model.layers[layer + 1].fprop(l , indices, updates)\n",
    "                    #print(sess.run(r)[0])\n",
    "                else:\n",
    "                    r = model.layers[layer + 1].fprop(l)\n",
    "            feed_dic[neuron] = r\n",
    "        all_probs = sess.run(feed_dic)\n",
    "        out_dic={}\n",
    "        for key in all_probs.keys():\n",
    "#             print(key)\n",
    "            probs = np.array(all_probs[key]).reshape((90,2))[:,1:].reshape((90))\n",
    "            clus = clustering(probs,samples, sens_params)\n",
    "            out_dic[key]= [len(clus) - 1 ]\n",
    "#             print(neuron)\n",
    "#             input(model_acc(sess, model,key,X,Y,layer_number,num_layers,update_list ))\n",
    "            \n",
    "            #out_dic[key].append(model_acc(sess, model,key,X,Y,layer_number,num_layers,update_list ))\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        return out_dic\n",
    "\n",
    "def get_rate(lay_name, layer_output):\n",
    "        def get_distance(vec1, vec2, size):\n",
    "            return abs(vec1-vec2).sum() / size\n",
    "            \n",
    "#         config = tf.ConfigProto()\n",
    "#         config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "#         sess = tf.Session(config = config)\n",
    "#         x = tf.placeholder(tf.float32, shape = input_shape)\n",
    "#         y = tf.placeholder(tf.float32, shape = (None, nb_classes))\n",
    "#         model = dnn(input_shape, nb_classes)   \n",
    "\n",
    "#         preds = model(x)\n",
    "#         saver = tf.train.Saver()\n",
    "#         model_path = model_path + dataset + \"/test.model\"\n",
    "#         saver.restore(sess, model_path)\n",
    "        max_dis = 0\n",
    "        epsillon = 10 ** -7\n",
    "        num_samples = len(layer_output[lay_name])\n",
    "\n",
    "        layer_ind = np.where(np.array(list(layer_output.keys())) == lay_name)[0][0]\n",
    "        for ind in range(layer_ind):\n",
    "            temp_dis = 0\n",
    "            if 'ReLU' in np.array(list(layer_output.keys()))[ind]:\n",
    "                layer_name = np.array(list(layer_output.keys()))[ind]\n",
    "                layer_size  = len(layer_output[layer_name][0][0])\n",
    "                distances = np.zeros((num_samples,num_samples))\n",
    "                for i in combinations(range(num_samples),2):\n",
    "                    distances[i[0],i[1]] = get_distance(layer_output[layer_name][i[0]],layer_output[layer_name][i[1]],layer_size)\n",
    "                if distances.max()> max_dis:\n",
    "                    max_dis = distances.max()\n",
    "        distances = np.zeros((num_samples,num_samples))\n",
    "        for i in combinations(range(num_samples),2):\n",
    "            distances[i[0],i[1]] = get_distance(layer_output[lay_name][i[0]],layer_output[lay_name][i[1]],len(layer_output[lay_name][0][0]))\n",
    "        cur_dis = distances.max()\n",
    "\n",
    "        change_rate = (cur_dis - max_dis ) / (max_dis + epsillon)      \n",
    "        return change_rate \n",
    "\n",
    "    \n",
    "    \n",
    "def model_acc(sess, model,model_path,input_shape, nb_classes,\n",
    "              dataset, sens_params,neuron,X,Y,layer_number,num_layers,update_list):\n",
    "        if  sess._closed:\n",
    "                config = tf.ConfigProto()\n",
    "                config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "                sess = tf.Session(config = config)\n",
    "                x = tf.placeholder(tf.float32, shape = input_shape)\n",
    "                y = tf.placeholder(tf.float32, shape = (None, nb_classes))\n",
    "                model = dnn(input_shape, nb_classes)   \n",
    "\n",
    "                preds = model(x)\n",
    "                saver = tf.train.Saver()\n",
    "                #model_path = model_path + dataset + \"/test.model\"\n",
    "                saver.restore(sess, model_path)\n",
    "        feed_dic = {}\n",
    "         \n",
    "        for layer in range(0,num_layers - 1,2):\n",
    "            if layer == 0:\n",
    "                l = model.layers[layer].fprop(X.astype('float32'))\n",
    "            else:\n",
    "                l = model.layers[layer].fprop(r)\n",
    "           \n",
    "            if layer + 1 == (layer_number * 2) - 1:\n",
    "\n",
    "                indices = []\n",
    "                for instance in range(l.shape[0]):                       \n",
    "                    indices.append([ instance, neuron])\n",
    "                \n",
    "                updates = [ update_list[ neuron ] ] * l.shape[0]\n",
    "                \n",
    "                r = model.layers[layer + 1].fprop(l , indices, updates)\n",
    "                #input(sess.run(r)[0])\n",
    "            else:\n",
    "                r = model.layers[layer + 1].fprop(l)             \n",
    "\n",
    "        all_probs = sess.run(r)\n",
    "        out_class = []\n",
    "        for out in all_probs:\n",
    "            out_class.append(np.argmax(out))\n",
    "        truth_val = []\n",
    "        for tr in Y:\n",
    "                truth_val.append(np.argmax(tr))\n",
    "        acc=0\n",
    "        for i in range(len(out_class)):\n",
    "            if out_class[i]==truth_val[i]:\n",
    "                acc +=1\n",
    "        accuracy = round(acc/len(out_class),3)\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        #print(accuracy)\n",
    "        return accuracy    \n",
    "#-------------------------------------------\n",
    "    \n",
    "def dnn_fair_testing(dataset, sens_params, model_path):\n",
    "\n",
    "    data = {\"census\":census_data, \"credit\":credit_data, \"bank\":bank_data, \"compas\":compas_data, \n",
    "            \"default\": default_data, \"heart\":heart_data}\n",
    "    data_config = {\"census\":census, \"credit\":credit, \"bank\":bank, \"compas\":compas, \"default\":default,\n",
    "                  \"heart\":heart}\n",
    "    # prepare the testing data and model\n",
    "    X, Y, input_shape, nb_classes = data[dataset]()\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "#     config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "#     config.allow_soft_placement= True\n",
    "\n",
    "\n",
    "    sess = tf.Session(config=config)\n",
    "    x = tf.placeholder(tf.float32, shape=input_shape)\n",
    "    y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n",
    "    model = dnn(input_shape, nb_classes)   \n",
    "\n",
    "    preds = model(x)\n",
    "    saver = tf.train.Saver()\n",
    "    model_path = model_path + dataset + \"/test.model\"\n",
    "    saver.restore(sess, model_path)\n",
    "    input_df=pd.read_csv('../results/census/final_disc_instances_k_maxk_40.csv',header='infer')\n",
    "    sample_df=input_df.copy()\n",
    "    sample_df_rand = sample_df.sample(n=6300,axis=0,random_state=np.random.RandomState())\n",
    "    sample_df_maxk = sample_df.sort_values(by='#k',ascending=False).head(700)\n",
    "    sample_df = pd.concat([sample_df_rand,sample_df_maxk])\n",
    "    ini_k_samples = sample_df['#k']\n",
    "    sample_df=sample_df.drop(columns=['#disc','#k']) \n",
    "    samples = sample_df.to_numpy()\n",
    "    print(len(samples))\n",
    "    np.save('../results/census/samples_6300_700.npy', samples)\n",
    "    update_df=pd.read_csv('../results/census/dataset_layer2_out.csv')\n",
    "#     update_list_mean = update_df.mean()\n",
    "#     update_list_max = update_df.max()\n",
    "#     update_list_mode = update_df.mode()\n",
    "    #-----------------------------\n",
    "    update_min = update_df.min()\n",
    "    update_max = update_df.max()\n",
    "    update_mean = update_df.mean()\n",
    "    update_std = update_df.std()\n",
    "    update_list=[]\n",
    "    update_list.append(update_min)\n",
    "    rand_point = np.sort(np.random.random(4))\n",
    "    for i in range(4):\n",
    "        update_list.append(rand_point[i] * update_mean)\n",
    "    update_list.append(update_mean)\n",
    "    rand_point = np.sort(np.random.random(3))\n",
    "    for i in range(3):\n",
    "        update_list.append(update_mean + rand_point[i] * update_std)\n",
    "    update_list.append(update_mean + update_std +  np.random.random(1)[0] * update_std)        \n",
    "    update_list.append(update_max)\n",
    "    #----------------------------------\n",
    "    layer_number = 2 #supposed to come from layer locator\n",
    "    layer_size = model.layers[(layer_number*2) - 1].input_shape[1]\n",
    "    layer_name = model.layers[(layer_number*2) - 1]\n",
    "    num_layers = len(model.layers)\n",
    "\n",
    "    all_dic={}\n",
    "    accu_neuron={}\n",
    "    acc_try={}\n",
    "    sample_ind = 0\n",
    "    for sample in samples:       \n",
    "        update_list_man = np.array([0] * layer_size)\n",
    "        m_samples=m_instance( np.array([sample]), sens_params, data_config[dataset])\n",
    "        change_dic={}\n",
    "        for i in range(11):\n",
    "            update_list_man = update_list[i]               \n",
    "            x=neuron_locator(sess, model, m_samples, layer_number,model_path,\n",
    "                           input_shape, nb_classes, dataset, sens_params, update_list_man,X,Y )\n",
    "            if sample_ind ==0:\n",
    "                accu_neuron={}\n",
    "                for neuron in range(len(update_list_man)):\n",
    "                    accu_neuron[neuron] = model_acc(sess, model,model_path,\n",
    "                                     input_shape, nb_classes, dataset, sens_params,\n",
    "                                     neuron,X,Y,layer_number,num_layers,update_list_man)\n",
    "                acc_try[i]= accu_neuron                 \n",
    "            change_dic[i]=x   \n",
    "        all_dic[sample_ind]=change_dic\n",
    "        print(sample_ind)\n",
    "        sample_ind+=1\n",
    "        \n",
    "     \n",
    "    #print(model_acc(sess, model,neuron,X,Y,layer_number,num_layers,update_list_man ))\n",
    "    np.save('../results/census/ini_k_samples_6300_700.npy', np.array(ini_k_samples))\n",
    "    np.save('../results/census/accu_dic_6300_700.npy', acc_try) \n",
    "    np.save('../results/census/all_dic_6300_700.npy', all_dic)   \n",
    "              \n",
    " \n",
    "        \n",
    "def main(argv=None):\n",
    "    dnn_fair_testing(dataset = FLAGS.dataset, \n",
    "                     sens_params = FLAGS.sens_params,\n",
    "                     model_path  = FLAGS.model_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    flags.DEFINE_string(\"dataset\", \"census\", \"the name of dataset\")\n",
    "    flags.DEFINE_string('model_path', '../models/', 'the path for testing model')\n",
    "    flags.DEFINE_integer('cluster_num', 4, 'the number of clusters to form as well as the number of centroids to generate')\n",
    "    flags.DEFINE_list('sens_params',[9,8,1],'sensitive parameters index.1 for age, 9 for gender, 8 for race')\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-1444e681885d>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['init_k'][sample+i]=ini_k_random_samples[int(sample/len_each_try)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.003\n",
      "1   0.0\n",
      "2   0.0\n",
      "3   -0.054\n",
      "4   -0.006\n",
      "5   -0.007\n",
      "6   0.012\n",
      "7   -0.047\n",
      "8   0.0\n",
      "9   -0.181\n",
      "10   -0.023\n",
      "11   0.0\n",
      "12   -0.034\n",
      "13   -0.062\n",
      "14   0.075\n",
      "15   0.146\n",
      "16   0.0\n",
      "17   -0.023\n",
      "18   -0.065\n",
      "19   -0.029\n",
      "20   0.0\n",
      "21   -0.043\n",
      "22   -0.051\n",
      "23   -0.023\n",
      "24   0.124\n",
      "25   -0.083\n",
      "26   -0.072\n",
      "27   -0.001\n",
      "28   -0.02\n",
      "29   -0.0\n",
      "30   -0.02\n",
      "31   -0.046\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "accu_dic=dict(np.load('../results/census/accu_dic_900_100.npy',allow_pickle=True).item())  \n",
    "all_dic=dict(np.load('../results/census/all_dic_900_100.npy',allow_pickle=True).item())\n",
    "ini_k_random_samples = np.load('../results/census/ini_k_samples_900_100.npy')\n",
    "df_acc =  pd.DataFrame(columns=['force','neuron','acc'],dtype='float')\n",
    "df_analysis = pd.DataFrame(columns=['sample','force','neuron','K'],dtype='int32')\n",
    "for sample in all_dic.keys():\n",
    "    for force in all_dic[0].keys():\n",
    "        for neuron in all_dic[0][0].keys():\n",
    "            df_analysis = df_analysis.append({'sample':sample,'force':force,\n",
    "                                              'neuron':neuron,'K':all_dic[sample][force][neuron][0]},\n",
    "                                               ignore_index=True)\n",
    "            if sample == 0:\n",
    "                df_acc = df_acc.append({'force':force,'neuron':neuron,\n",
    "                                'acc':accu_dic[force][neuron]},\n",
    "                                           ignore_index=True)\n",
    "                \n",
    "df_test =  df_analysis.copy() \n",
    "df_test['acc'] = list(df_acc['acc']) * len(df_test['sample'].unique())\n",
    "df_test['init_k'] = 0\n",
    "len_each_try = len(df_test.loc[df_test['sample']==0])\n",
    "for sample in range(0,len(df_test['sample']),len_each_try):\n",
    "    for i in range(len_each_try):\n",
    "        df_test['init_k'][sample+i]=ini_k_random_samples[int(sample/len_each_try)]\n",
    "R_act   = []\n",
    "R_deact = []\n",
    "diff_R  = []\n",
    "ini_acc = 0.881\n",
    "acc_e = 0.05\n",
    "for neuron in range(32):\n",
    "    k_deact = df_test.loc[(df_test['neuron']==neuron) & (df_test['force']==0) & \\\n",
    "                          (df_test['acc'] >= ini_acc - acc_e)]['K'].mean()\n",
    "    k_act   = df_test.loc[(df_test['neuron']==neuron) & (df_test['force'] > 0) & \\\n",
    "                          (df_test['acc'] >= ini_acc - acc_e)]['K'].mean()\n",
    "    k_init  = df_test.loc[(df_test['neuron']==neuron) & (df_test['acc'] >= ini_acc - acc_e)]['init_k'].mean()\n",
    "    R_act_temp   = (k_act - k_init) / k_init\n",
    "    R_deact_temp = (k_deact - k_init) / k_init\n",
    "    diff_R_temp  = R_act_temp - R_deact_temp\n",
    "    R_act.append(R_act_temp)\n",
    "    R_deact.append(R_deact_temp)\n",
    "    diff_R.append(diff_R_temp)\n",
    "\n",
    "for i in range(len(diff_R)):\n",
    "    print(i,' ',round(diff_R[i],3))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.003\n",
      "1   0.0\n",
      "2   0.0\n",
      "3   -0.057\n",
      "4   -0.006\n",
      "5   -0.008\n",
      "6   -0.018\n",
      "7   -0.048\n",
      "8   0.0\n",
      "9   -0.193\n",
      "10   -0.021\n",
      "11   0.005\n",
      "12   -0.034\n",
      "13   -0.069\n",
      "14   0.082\n",
      "15   0.153\n",
      "16   0.0\n",
      "17   -0.022\n",
      "18   -0.07\n",
      "19   -0.027\n",
      "20   0.0\n",
      "21   -0.041\n",
      "22   -0.052\n",
      "23   -0.023\n",
      "24   0.133\n",
      "25   -0.085\n",
      "26   -0.078\n",
      "27   0.002\n",
      "28   -0.02\n",
      "29   -0.0\n",
      "30   -0.022\n",
      "31   -0.046\n"
     ]
    }
   ],
   "source": [
    "R_act   = []\n",
    "R_deact = []\n",
    "diff_R  = []\n",
    "ini_acc = 0.881\n",
    "acc_e = 0.05\n",
    "for neuron in range(32):\n",
    "    k_deact = df_test.loc[(df_test['neuron']==neuron) & (df_test['force']<=1) & \\\n",
    "                          (df_test['acc'] >= ini_acc - acc_e)]['K'].mean()\n",
    "    k_act   = df_test.loc[(df_test['neuron']==neuron) & (df_test['force'] > 1) & \\\n",
    "                          (df_test['acc'] >= ini_acc - acc_e)]['K'].mean()\n",
    "    k_init  = df_test.loc[(df_test['neuron']==neuron) & (df_test['acc'] >= ini_acc - acc_e)]['init_k'].mean()\n",
    "    R_act_temp   = (k_act - k_init) / k_init\n",
    "    R_deact_temp = (k_deact - k_init) / k_init\n",
    "    diff_R_temp  = R_act_temp - R_deact_temp\n",
    "    R_act.append(R_act_temp)\n",
    "    R_deact.append(R_deact_temp)\n",
    "    diff_R.append(diff_R_temp)\n",
    "\n",
    "for i in range(len(diff_R)):\n",
    "    print(i,' ',round(diff_R[i],3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -0.003\n",
      "1   0.0\n",
      "2   0.0\n",
      "3   -0.054\n",
      "4   -0.006\n",
      "5   -0.007\n",
      "6   0.012\n",
      "7   -0.047\n",
      "8   0.0\n",
      "9   -0.181\n",
      "10   -0.023\n",
      "11   0.0\n",
      "12   -0.034\n",
      "13   -0.062\n",
      "14   0.075\n",
      "15   0.146\n",
      "16   0.0\n",
      "17   -0.023\n",
      "18   -0.065\n",
      "19   -0.029\n",
      "20   0.0\n",
      "21   -0.043\n",
      "22   -0.051\n",
      "23   -0.023\n",
      "24   0.124\n",
      "25   -0.083\n",
      "26   -0.072\n",
      "27   -0.001\n",
      "28   -0.02\n",
      "29   -0.0\n",
      "30   -0.02\n",
      "31   -0.046\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(diff_R)):\n",
    "    print(i,' ',round(diff_R[i],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron  0\n",
      "Num samples force 0 =  2000\n",
      "19.9       0.878\n",
      "Numb samples force 1 =  8000\n",
      "19.849       0.8781111111111112\n",
      "------------\n",
      "Neuron  1\n",
      "Num samples force 0 =  2000\n",
      "20.075       0.8810000000000001\n",
      "Numb samples force 1 =  9000\n",
      "20.075       0.8810000000000002\n",
      "------------\n",
      "Neuron  2\n",
      "Num samples force 0 =  2000\n",
      "20.075       0.8810000000000001\n",
      "Numb samples force 1 =  9000\n",
      "20.075       0.8810000000000002\n",
      "------------\n",
      "Neuron  3\n",
      "Num samples force 0 =  2000\n",
      "18.268       0.8729999999999998\n",
      "Numb samples force 1 =  8000\n",
      "17.18111111111111       0.8531111111111113\n",
      "------------\n",
      "Neuron  4\n",
      "Num samples force 0 =  2000\n",
      "20.077       0.8810000000000001\n",
      "Numb samples force 1 =  8000\n",
      "19.962666666666667       0.8810000000000001\n",
      "------------\n",
      "Neuron  5\n",
      "Num samples force 0 =  2000\n",
      "19.735       0.8810000000000001\n",
      "Numb samples force 1 =  8000\n",
      "19.598333333333333       0.880888888888889\n",
      "------------\n",
      "Neuron  6\n",
      "Num samples force 0 =  2000\n",
      "17.701       0.84\n",
      "Numb samples force 1 =  9000\n",
      "17.9354       0.8577\n",
      "------------\n",
      "Neuron  7\n",
      "Num samples force 0 =  2000\n",
      "19.705       0.875\n",
      "Numb samples force 1 =  8000\n",
      "18.764777777777777       0.8711111111111111\n",
      "------------\n",
      "Neuron  8\n",
      "Num samples force 0 =  2000\n",
      "20.075       0.8810000000000001\n",
      "Numb samples force 1 =  9000\n",
      "20.075       0.8810000000000002\n",
      "------------\n",
      "Neuron  9\n",
      "Num samples force 0 =  2000\n",
      "20.497       0.878\n",
      "Numb samples force 1 =  9000\n",
      "16.8675       0.8657\n",
      "------------\n",
      "Neuron  10\n",
      "Num samples force 0 =  2000\n",
      "19.793       0.878\n",
      "Numb samples force 1 =  8000\n",
      "19.332555555555555       0.8729999999999998\n",
      "------------\n",
      "Neuron  11\n",
      "Num samples force 0 =  2000\n",
      "18.538       0.8800000000000002\n",
      "Numb samples force 1 =  7000\n",
      "18.54275       0.857625\n",
      "------------\n",
      "Neuron  12\n",
      "Num samples force 0 =  2000\n",
      "20.458       0.8640000000000002\n",
      "Numb samples force 1 =  7000\n",
      "19.767       0.8648750000000001\n",
      "------------\n",
      "Neuron  13\n",
      "Num samples force 0 =  2000\n",
      "20.653       0.8770000000000002\n",
      "Numb samples force 1 =  9000\n",
      "19.4044       0.8726\n",
      "------------\n",
      "Neuron  14\n",
      "Num samples force 0 =  2000\n",
      "18.438       0.8659999999999998\n",
      "Numb samples force 1 =  7000\n",
      "19.949       0.8623749999999999\n",
      "------------\n",
      "Neuron  15\n",
      "Num samples force 0 =  2000\n",
      "16.244       0.8520000000000002\n",
      "Numb samples force 1 =  7000\n",
      "19.172375       0.8541249999999999\n",
      "------------\n",
      "Neuron  16\n",
      "Num samples force 0 =  2000\n",
      "20.075       0.8810000000000001\n",
      "Numb samples force 1 =  9000\n",
      "20.075       0.8810000000000002\n",
      "------------\n",
      "Neuron  17\n",
      "Num samples force 0 =  2000\n",
      "19.823       0.8770000000000002\n",
      "Numb samples force 1 =  8000\n",
      "19.368333333333332       0.8753333333333335\n",
      "------------\n",
      "Neuron  18\n",
      "Num samples force 0 =  2000\n",
      "19.799       0.8699999999999998\n",
      "Numb samples force 1 =  5000\n",
      "18.4965       0.8551666666666666\n",
      "------------\n",
      "Neuron  19\n",
      "Num samples force 0 =  2000\n",
      "19.813       0.8670000000000002\n",
      "Numb samples force 1 =  8000\n",
      "19.23788888888889       0.8686666666666667\n",
      "------------\n",
      "Neuron  20\n",
      "Num samples force 0 =  2000\n",
      "20.075       0.8810000000000001\n",
      "Numb samples force 1 =  9000\n",
      "20.075       0.8810000000000002\n",
      "------------\n",
      "Neuron  21\n",
      "Num samples force 0 =  2000\n",
      "19.595       0.8800000000000002\n",
      "Numb samples force 1 =  8000\n",
      "18.735333333333333       0.8714444444444445\n",
      "------------\n",
      "Neuron  22\n",
      "Num samples force 0 =  2000\n",
      "20.359       0.876\n",
      "Numb samples force 1 =  8000\n",
      "19.327111111111112       0.8728888888888889\n",
      "------------\n",
      "Neuron  23\n",
      "Num samples force 0 =  2000\n",
      "19.013       0.876\n",
      "Numb samples force 1 =  7000\n",
      "18.5435       0.873125\n",
      "------------\n",
      "Neuron  24\n",
      "Num samples force 0 =  2000\n",
      "18.056       0.8680000000000002\n",
      "Numb samples force 1 =  9000\n",
      "20.5396       0.866\n",
      "------------\n",
      "Neuron  25\n",
      "Num samples force 0 =  2000\n",
      "20.157       0.8810000000000001\n",
      "Numb samples force 1 =  8000\n",
      "18.48188888888889       0.872\n",
      "------------\n",
      "Neuron  26\n",
      "Num samples force 0 =  2000\n",
      "19.596       0.8670000000000002\n",
      "Numb samples force 1 =  9000\n",
      "18.1551       0.8674\n",
      "------------\n",
      "Neuron  27\n",
      "Num samples force 0 =  2000\n",
      "19.5       0.875\n",
      "Numb samples force 1 =  6000\n",
      "19.477857142857143       0.8692857142857143\n",
      "------------\n",
      "Neuron  28\n",
      "Num samples force 0 =  2000\n",
      "19.899       0.875\n",
      "Numb samples force 1 =  8000\n",
      "19.492333333333335       0.8744444444444444\n",
      "------------\n",
      "Neuron  29\n",
      "Num samples force 0 =  2000\n",
      "20.075       0.8810000000000001\n",
      "Numb samples force 1 =  9000\n",
      "20.0737       0.8810000000000002\n",
      "------------\n",
      "Neuron  30\n",
      "Num samples force 0 =  2000\n",
      "20.247       0.8789999999999997\n",
      "Numb samples force 1 =  8000\n",
      "19.842111111111112       0.8769999999999997\n",
      "------------\n",
      "Neuron  31\n",
      "Num samples force 0 =  2000\n",
      "20.107       0.8800000000000002\n",
      "Numb samples force 1 =  7000\n",
      "19.178125       0.876125\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(32):\n",
    "    print('Neuron ',i)\n",
    "    print('Num samples force 0 = ',len(df_test.loc[(df_test['force']<=1) & \\\n",
    "                      (df_test['neuron']==i) & (df_test['acc']>0.83)]['K']))\n",
    "    print(df_test.loc[(df_test['force']==0) & \\\n",
    "                      (df_test['neuron']==i) & (df_test['acc']>0.83)]['K'].mean(),'     ',df_test.loc[(df_test['force']==0) &\\\n",
    "                (df_test['neuron']==i) & (df_test['acc']>0.82)]['acc'].mean())\n",
    "#     print(df_test.loc[(df_test['force']==0) &\\\n",
    "#                 (df_test['neuron']==i) & (df_test['acc']>0.82)]['acc'].mean())\n",
    "    \n",
    "    print('Numb samples force 1 = ',len(df_test.loc[(df_test['force']>1) & \\\n",
    "                      (df_test['neuron']==i) & (df_test['acc']>0.83)]['K']))\n",
    "    print(df_test.loc[(df_test['force']>=1) & \\\n",
    "                      (df_test['neuron']==i) & (df_test['acc']>0.83)]['K'].mean(),'     ',df_test.loc[(df_test['force']>=1) &\\\n",
    "                    (df_test['neuron']==i) & (df_test['acc']>0.83)]['acc'].mean())\n",
    "#     print(df_test.loc[(df_test['force']>=1) &\\\n",
    "#                     (df_test['neuron']==i) & (df_test['acc']>0.82)]['acc'].mean())\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_analysis_pivot=pd.pivot_table(df_analysis, values=['K','Accuracy'], index=['sample', 'force','neuron'])\n",
    "# df_analysis_pivot.loc[( 0, 0, 1),['K','Accuracy']]\n",
    "\n",
    "# accu_dic=dict(np.load('../results/census/accu_dic.npy',allow_pickle=True).item())\n",
    "# all_dic=dict(np.load('../results/census/all_dic.npy',allow_pickle=True).item())\n",
    "k_dic={}\n",
    "acc_dic={}\n",
    "for neuron in range(32):\n",
    "\n",
    "    N_k=pd.DataFrame(columns=range(0,10),dtype='int32')\n",
    "    N_acc=pd.DataFrame(columns=range(0,10),dtype='int32')\n",
    "    n_k=df_test[df_test['neuron']==neuron]\n",
    "    for force in range(10):\n",
    "\n",
    "        N_k[force]=n_k[n_k['force']==force]['K'].reset_index()['K']\n",
    "        N_acc[force]=n_k[n_k['force']==force]['acc'].reset_index()['acc']\n",
    "    \n",
    "    k_dic[neuron]=N_k\n",
    "    acc_dic[neuron]=N_acc\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# for key in k_dic.keys():\n",
    "#     k_dic[key]=pd.DataFrame(scaler.fit_transform(k_dic[key]))\n",
    "#     acc_dic[key]=pd.DataFrame(scaler.fit_transform(acc_dic[key]))   \n",
    "\n",
    "# df_analysis['Accuracy']=scaler.fit_transform(pd.DataFrame(df_analysis['Accuracy']))\n",
    "# df_analysis['K']=scaler.fit_transform(pd.DataFrame(df_analysis['K']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_test.loc[df_test['sample']==2]\n",
    "x['K']=scaler.fit_transform(pd.DataFrame(x['K']))\n",
    "x['acc']=scaler.fit_transform(pd.DataFrame(x['acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "import matplotlib.pyplot as plt\n",
    "x=df_test.loc[df_test['sample']==13]\n",
    "x['K']=scaler.fit_transform(pd.DataFrame(x['K']))\n",
    "x['acc']=scaler.fit_transform(pd.DataFrame(x['acc']))\n",
    "for n in range(10):\n",
    "    plt.plot(x[ df_test['force']==n]['neuron'], \n",
    "             scaler.fit_transform(pd.DataFrame(x[ x['force']==n]['acc'])),label = \"acc\")\n",
    "    plt.plot(x[ x['force']==n]['neuron'], \n",
    "             scaler.fit_transform(pd.DataFrame(x[ x['force']==n]['K'])),label = \"K\")\n",
    "    plt.xlabel('Neuron')\n",
    "    plt.ylabel('K')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "x1=x.loc[x['force']==0]['K']\n",
    "x2 =x.loc[x['force']==0]['acc']\n",
    "fig = px.line( x=range(32), y=x1, title=\"Unsorted Input\") \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
