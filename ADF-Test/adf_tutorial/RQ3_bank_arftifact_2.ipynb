{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_neuron 3 16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e096a6eb0dfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../models/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'the path for testing model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sens_params'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sensitive parameters index.1 for age, 9 for gender, 8 for race'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e096a6eb0dfb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m     dnn_fair_testing(dataset = FLAGS.dataset, \n\u001b[0m\u001b[1;32m    373\u001b[0m                      \u001b[0msens_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msens_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                      model_path  = FLAGS.model_path)\n",
      "\u001b[0;32m<ipython-input-1-e096a6eb0dfb>\u001b[0m in \u001b[0;36mdnn_fair_testing\u001b[0;34m(dataset, sens_params, model_path)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;31m#         np.save('../results/'+dataset+'/OurTool/RQ3/table2/R_diffR_'+str(num_samples)+'_'+str(trial)+'.npy',diff_R)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../results/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/OurTool/RQ3/table2/RQ3_table_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "import  os\n",
    "#import psutil\n",
    "# p = psutil.Process(os.getpid())\n",
    "# p.cpu_affinity(0)\n",
    "import numpy as np\n",
    "from itertools import product, combinations\n",
    "import tensorflow.compat.v1 as tf \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from tensorflow.python.platform import flags\n",
    "from adf_data.bank import bank_data\n",
    "from adf_model.tutorial_models import dnn\n",
    "from adf_utils.utils_tf import model_prediction, model_argmax , layer_out, model_eval\n",
    "from adf_utils.config import bank\n",
    "from IPython.display import clear_output\n",
    "import csv\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "       \n",
    "def m_instance( sample, sens_params, conf):\n",
    "    index = []\n",
    "    m_sample = []\n",
    "    for sens in sens_params:\n",
    "        index.append([i for i in range(conf.input_bounds[sens - 1][0], conf.input_bounds[sens-1][1] + 1)])\n",
    "      \n",
    "    for ind in list(product(*index)):     \n",
    "        temp = sample.copy()\n",
    "        for i in range(len(sens_params)):\n",
    "            temp[0][sens_params[i]-1] = ind[i]\n",
    "        m_sample.append(temp)\n",
    "    return np.array(m_sample)\n",
    "    \n",
    "def clustering(probs,m_sample, sens_params, epsilon=0.025):\n",
    "    cluster_dic = {}\n",
    "    cluster_dic['Seed'] = m_sample[0][0]\n",
    "    bins= np.arange(0, 1, epsilon )\n",
    "    digitized = np.digitize(probs, bins) - 1\n",
    "    for  k in range(len(digitized)):\n",
    "\n",
    "        if digitized[k] not in cluster_dic.keys():        \n",
    "            cluster_dic[digitized[k]]=[ [m_sample[k][0][j - 1] for j in sens_params]]\n",
    "        else:\n",
    "            cluster_dic[digitized[k]].append( [m_sample[k][0][j - 1] for j in sens_params])\n",
    "    return cluster_dic \n",
    "\n",
    "    \n",
    "def pred_prob(sess, x, preds, m_sample, input_shape):\n",
    "        probs = model_prediction(sess, x, preds, np.array(m_sample).reshape(len(m_sample),\n",
    "                                    input_shape[1]))[:,1:2].reshape(len(m_sample))\n",
    "        return probs        \n",
    "        \n",
    "def neuron_locator(sess, model, samples, layer_number,model_path, input_shape, \n",
    "                   nb_classes, dataset, sens_params, update_list  ):\n",
    "        \n",
    "        if  sess._closed:\n",
    "#             config = tf.ConfigProto()\n",
    "#             config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "            config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "            config.allow_soft_placement= True            \n",
    "            sess   = tf.Session(config = config)\n",
    "            x      = tf.placeholder(tf.float32, shape = input_shape)\n",
    "            y      = tf.placeholder(tf.float32, shape = (None, nb_classes))\n",
    "            model  = dnn(input_shape, nb_classes)   \n",
    "            preds  = model(x)\n",
    "            saver  = tf.train.Saver()\n",
    "            saver.restore(sess, model_path)\n",
    "            \n",
    "        num_layers = len(model.layers)\n",
    "        feed_dic = {}\n",
    "        for neuron in range(len(update_list)):           \n",
    "            for layer in range(0,num_layers - 1,2):\n",
    "                if layer == 0:\n",
    "                    l = model.layers[layer].fprop(samples.astype('float32'))\n",
    "                else:\n",
    "                    l = model.layers[layer].fprop(r)                   \n",
    "                if layer + 1 == (layer_number * 2) - 1:\n",
    "                    indices = []\n",
    "                    for instance in range(l.shape[0]):                       \n",
    "                        indices.append([ instance, 0, neuron])       \n",
    "                    updates = [ update_list[ neuron ] ] * l.shape[0]\n",
    "                    r = model.layers[layer + 1].fprop(l , indices, updates)\n",
    "                else:\n",
    "                    r = model.layers[layer + 1].fprop(l)\n",
    "            feed_dic[neuron] = r\n",
    "        all_probs = sess.run(feed_dic)\n",
    "        out_dic   = {}\n",
    "        for key in all_probs.keys():\n",
    "            probs = np.array(all_probs[key]).reshape((9,2))[:,1:].reshape((9))\n",
    "            clus  = clustering(probs,samples, sens_params)\n",
    "            out_dic[key] = [len(clus) - 1 ]\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        return out_dic\n",
    "    \n",
    "def model_acc(sess, model,model_path,input_shape, nb_classes,\n",
    "              dataset, sens_params,neuron,X,Y,layer_number,num_layers,update_list):\n",
    "        \n",
    "        if  sess._closed:\n",
    "#                 config = tf.ConfigProto()\n",
    "#                 config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "                config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "                config.allow_soft_placement= True\n",
    "                sess   = tf.Session(config = config)\n",
    "                x      = tf.placeholder(tf.float32, shape = input_shape)\n",
    "                y      = tf.placeholder(tf.float32, shape = (None, nb_classes))\n",
    "                model  = dnn(input_shape, nb_classes)   \n",
    "                preds  = model(x)\n",
    "                saver  = tf.train.Saver()\n",
    "                saver.restore(sess, model_path)\n",
    "        feed_dic = {}        \n",
    "        for layer in range(0,num_layers - 1,2):\n",
    "            if layer == 0:\n",
    "                l = model.layers[layer].fprop(X.astype('float32'))\n",
    "            else:\n",
    "                l = model.layers[layer].fprop(r)          \n",
    "            if layer + 1 == (layer_number * 2) - 1:\n",
    "                indices = []\n",
    "                for instance in range(l.shape[0]):                       \n",
    "                    indices.append([ instance, neuron])                \n",
    "                updates = [ update_list[ neuron ] ] * l.shape[0]                \n",
    "                r = model.layers[layer + 1].fprop(l , indices, updates)\n",
    "            else:\n",
    "                r = model.layers[layer + 1].fprop(l)             \n",
    "        all_probs = sess.run(r)\n",
    "        out_class = []\n",
    "        for out in all_probs:\n",
    "            out_class.append(np.argmax(out))\n",
    "        truth_val = []\n",
    "        for tr in Y:\n",
    "                truth_val.append(np.argmax(tr))\n",
    "        acc = 0\n",
    "        for i in range(len(out_class)):\n",
    "            if out_class[i] == truth_val[i]:\n",
    "                acc += 1\n",
    "        accuracy = round(acc/len(out_class),3)\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        return accuracy \n",
    "\n",
    "def get_rate(sess, model, model_path, input_shape, nb_classes,\n",
    "              dataset, lay_name, layer_output):\n",
    "        \n",
    "        def get_distance(vec1, vec2, size):\n",
    "            return abs(vec1 - vec2).sum() / size\n",
    "        \n",
    "        max_dis = 0\n",
    "        epsillon = 10 ** -7\n",
    "        num_samples = len(layer_output[lay_name])\n",
    "        #print('lay_name',lay_name)\n",
    "        layer_ind = np.where(np.array(list(layer_output.keys())) == lay_name)[0][0]\n",
    "\n",
    "        for ind in range(layer_ind):\n",
    "            temp_dis = 0\n",
    "            if 'ReLU' in np.array(list(layer_output.keys()))[ind]:\n",
    "                layer_name = np.array(list(layer_output.keys()))[ind]\n",
    "                layer_size  = len(layer_output[layer_name][0][0])\n",
    "                distances = np.zeros((num_samples,num_samples))\n",
    "                \n",
    "                for i in combinations(range(num_samples),2):\n",
    "                    distances[i[0],i[1]] = get_distance(layer_output[layer_name][i[0]],\n",
    "                                                        layer_output[layer_name][i[1]],layer_size)\n",
    "                if distances.max()> max_dis:\n",
    "                    max_dis = distances.max()                                      \n",
    "        distances = np.zeros((num_samples,num_samples))       \n",
    "        for i in combinations(range(num_samples),2):\n",
    "            distances[i[0],i[1]] = get_distance(layer_output[lay_name][i[0]],layer_output[lay_name][i[1]],len(layer_output[lay_name][0][0]))\n",
    "        cur_dis = distances.max()\n",
    "        change_rate = (cur_dis - max_dis ) / (max_dis + epsillon)\n",
    "        return change_rate\n",
    "    \n",
    "def layer_locator(sess, model, model_path,sens_params, input_shape, nb_classes,\n",
    "              dataset,conf, samples):\n",
    "        if  sess._closed:\n",
    "    #                 config = tf.ConfigProto()\n",
    "    #                 config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "            config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "            config.allow_soft_placement= True\n",
    "            sess   = tf.Session(config = config)\n",
    "            x      = tf.placeholder(tf.float32, shape = input_shape)\n",
    "            y      = tf.placeholder(tf.float32, shape = (None, nb_classes))\n",
    "            model  = dnn(input_shape, nb_classes)   \n",
    "            preds  = model(x)\n",
    "            saver  = tf.train.Saver()\n",
    "            saver.restore(sess, model_path)\n",
    "            \n",
    "        layer_list = []\n",
    "        layer_rate = []\n",
    "        for sample in samples:            \n",
    "            samples = m_instance( np.array([sample]) , sens_params, conf)\n",
    "            layer_output = layer_out(sess,model,np.array(samples).astype('float32')) \n",
    "            temp_list = []\n",
    "            for layer in layer_output.keys():\n",
    "                if 'ReLU' in layer:\n",
    "                    temp_rate = get_rate(sess, model, model_path, input_shape, nb_classes,\n",
    "                                          dataset,layer, layer_output)\n",
    "                    temp_list.append(temp_rate) \n",
    "            layer_rate.append(max(temp_list[1:]))\n",
    "                              \n",
    "            layer_list.append((np.argmax(np.array(temp_list[1:])) + 2 ))\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        print()\n",
    "        return stats.mode(layer_list)[0][0], np.array(layer_rate).mean()    \n",
    "#-------------------------------------------\n",
    "    \n",
    "def dnn_fair_testing(dataset, sens_params, model_path):\n",
    "\n",
    "    data = {\"bank\":bank_data}\n",
    "           \n",
    "    data_config = {\"bank\":bank}\n",
    "    global RQ3_table, layer_numbers, layer_influence\n",
    "    # prepare the testing data and model\n",
    "    X, Y, input_shape, nb_classes = data[dataset]()\n",
    "    tf.set_random_seed(1234)\n",
    "    layer_numbers=[]\n",
    "    layer_influence = []\n",
    "    RQ3_table = []\n",
    "    for trial in range(2):\n",
    "        config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "        config.allow_soft_placement= True\n",
    "        sess  = tf.Session(config = config)\n",
    "        x     = tf.placeholder(tf.float32, shape = input_shape)\n",
    "        y     = tf.placeholder(tf.float32, shape = (None, nb_classes))\n",
    "        model = dnn(input_shape, nb_classes)   \n",
    "        preds = model(x)\n",
    "        saver = tf.train.Saver()\n",
    "        model_path ='../models/'\n",
    "        model_path = model_path + dataset + \"/test.model\"\n",
    "        saver.restore(sess, model_path)\n",
    "        eval_params = {'batch_size': 128}\n",
    "        ini_acc = round(model_eval(sess, x, y, preds, X, Y, args=eval_params),3)\n",
    "        time1 = time.time()\n",
    "    # Loading the result of QID\n",
    "        layer_output = layer_out(sess,model,X.astype('float32'))\n",
    "        input_df  = pd.read_csv('../results/' + dataset + '/OurTool/RQ3/total_disc_'+str(trial)+'.csv',header='infer')\n",
    "        input_df = input_df.drop(columns=['Unnamed: 0'])       \n",
    "        sample_df = input_df.copy()\n",
    "        sample_df_rand = sample_df.sample(n = 50,axis = 0,random_state = np.random.RandomState())\n",
    "        sample_df_maxk = sample_df.sort_values(by = 'k',ascending=False).head(5)\n",
    "        sample_df = pd.concat([sample_df_rand,sample_df_maxk])\n",
    "        ini_k_samples = sample_df['k']\n",
    "        sample_df = sample_df.drop(columns = ['sh_entropy', 'k', 'disc', 'min_entropy']) \n",
    "        samples   = sample_df.to_numpy()\n",
    "        num_samples = len(samples)\n",
    "        layer_number, layer_rate = layer_locator(sess, model, model_path, sens_params, input_shape, nb_classes,\n",
    "              dataset,data_config[dataset], samples)\n",
    "        \n",
    "        layer_numbers.append(layer_number)\n",
    "        layer_influence.append(layer_rate)\n",
    "        #-----------------------------\n",
    "        update_df = layer_output['ReLU'+str((2*layer_number) -1 )]\n",
    "        update_min  = np.min(update_df,axis=0)\n",
    "#         update_max  = np.max(update_df,axis=0)\n",
    "        update_mean = np.mean(update_df,axis=0)\n",
    "#         update_std  = np.std(update_df,axis=0)\n",
    "        update_list = []\n",
    "        update_list.append(update_min)      \n",
    "        update_list.append(update_mean)\n",
    "        layer_size   = model.layers[(layer_number*2) - 1].input_shape[1]\n",
    "        layer_name   = model.layers[(layer_number*2) - 1]\n",
    "        num_layers   = len(model.layers)\n",
    "        num_trial = len(update_list)\n",
    "        all_dic = {}\n",
    "        accu_neuron = {}\n",
    "        acc_try = {}\n",
    "        sample_ind = 0\n",
    "        for sample in samples:       \n",
    "            update_list_man = np.array([0] * layer_size)\n",
    "            m_samples  = m_instance( np.array([sample]), sens_params, data_config[dataset])\n",
    "            change_dic = {}\n",
    "            for i in range(num_trial):\n",
    "                update_list_man = update_list[i]\n",
    "                x = neuron_locator(sess, model, m_samples, layer_number,model_path,\n",
    "                               input_shape, nb_classes, dataset, sens_params, update_list_man )\n",
    "                if sample_ind == 0:\n",
    "                    accu_neuron = {}\n",
    "                    for neuron in range(len(update_list_man)):\n",
    "                        accu_neuron[neuron] = model_acc(sess, model,model_path,\n",
    "                                         input_shape, nb_classes, dataset, sens_params,\n",
    "                                         neuron,X,Y,layer_number,num_layers,update_list_man)\n",
    "                    acc_try[i] = accu_neuron                 \n",
    "                change_dic[i] = x  \n",
    "            all_dic[sample_ind] = change_dic\n",
    "            clear_output(wait=True)\n",
    "            sample_ind += 1\n",
    "\n",
    "        # create the folder for storing the fairness testing result\n",
    "        if not os.path.exists('../results/'):\n",
    "            os.makedirs('../results/')\n",
    "        if not os.path.exists('../results/' + dataset + '/'):\n",
    "            os.makedirs('../results/' + dataset + '/')\n",
    "        if not os.path.exists('../results/' + dataset + '/OurTool/'):\n",
    "            os.makedirs('../results/' + dataset + '/OurTool/')\n",
    "        if not os.path.exists('../results/' + dataset + '/OurTool/RQ3/'):\n",
    "            os.makedirs('../results/' + dataset + '/OurTool/RQ3/')          \n",
    "        if not os.path.exists('../results/' + dataset + '/OurTool/RQ3/table2/'):\n",
    "            os.makedirs('../results/' + dataset + '/OurTool/RQ3/table2/')\n",
    "#         np.save('../results/'+dataset+'/OurTool/RQ3/table2/inik_'+str(num_samples)+'_'+str(trial)+'.npy',\n",
    "#                 np.array(ini_k_samples))\n",
    "#         np.save('../results/'+dataset+'/OurTool/RQ3/table2/accu_dic_'+str(num_samples)+'_'+str(trial)+'.npy',\n",
    "#                 acc_try) \n",
    "#         np.save('../results/'+dataset+'/OurTool/RQ3/table2/all_dic_'+str(num_samples)+'_'+str(trial)+'.npy', \n",
    "#                 all_dic)   \n",
    "        accu_dic =  acc_try \n",
    "        ini_k = np.array(ini_k_samples)\n",
    "        num_samples = len(all_dic.keys())\n",
    "        num_force   = len(all_dic[0].keys())\n",
    "        num_neuron  = len(all_dic[0][0].keys())\n",
    "        print('num_neuron',layer_number,num_neuron)\n",
    "        ini_k = np.repeat(ini_k, (num_force * num_neuron))\n",
    "        data  = np.zeros(((num_samples * num_force * num_neuron) ,4) , dtype = 'int32')\n",
    "        df    = pd.DataFrame(data,columns = ['sample','force','neuron','K'],dtype = 'int32')\n",
    "        sample_col = np.repeat(np.array([i for i in range(num_samples)]),(num_neuron * num_force))\n",
    "        force_col  = np.array([ int(i/num_neuron ) for i in range( num_neuron * num_force ) ] * num_samples)\n",
    "        neuron_col = np.array([i for i in range( num_neuron )] * ( num_samples*num_force ))\n",
    "        df['sample'] = sample_col\n",
    "        df['force']  = force_col\n",
    "        df['neuron'] = neuron_col\n",
    "        df['acc'] = 0\n",
    "        acc = pd.DataFrame(accu_dic).transpose().to_numpy()\n",
    "        acc = acc.reshape(acc.shape[0] * acc.shape[1],)\n",
    "        for i in range(len(all_dic.keys())):\n",
    "            temp = pd.DataFrame(all_dic[i]).transpose().to_numpy()\n",
    "            temp = temp.reshape(((len(all_dic[0][0].keys())) * len(all_dic[0].keys()),))   \n",
    "            df.loc[df.loc[(df['sample'] == i) ].index,'acc'] = acc\n",
    "            df.loc[df.loc[(df['sample'] == i) ].index,'K'] = temp\n",
    "        df['K'] = df['K'].transform(lambda x:x[0])\n",
    "        df['init_k'] = ini_k\n",
    "\n",
    "        R_act   = []\n",
    "        R_deact = []\n",
    "        diff_R  = []\n",
    "        acc_e   = 0.05\n",
    "        for neuron in range(num_neuron):\n",
    "            k_deact = df.loc[(df['neuron'] == neuron) & (df['force'] == 0) & \\\n",
    "                                  (df['acc'] >= ini_acc - acc_e)]['K'].mean()\n",
    "            k_act   = df.loc[(df['neuron'] == neuron) & (df['force'] == 1) & \\\n",
    "                                  (df['acc'] >= ini_acc - acc_e)]['K'].mean()\n",
    "            k_init  = df.loc[(df['neuron'] == neuron) & (df['acc'] >= ini_acc - acc_e)]['init_k'].mean()\n",
    "            R_act_temp   = (k_act - k_init) / k_init\n",
    "            R_deact_temp = (k_deact - k_init) / k_init\n",
    "            diff_R_temp  = R_act_temp - R_deact_temp\n",
    "            R_act.append(R_act_temp)\n",
    "            R_deact.append(R_deact_temp)\n",
    "            diff_R.append(diff_R_temp)\n",
    "\n",
    "        RQ3_table.append(diff_R)\n",
    "#         df.to_csv('../results/'+dataset+'/OurTool/RQ3/table2/df_'+str(num_samples)+'_'+str(trial)+'.csv',index=False)\n",
    "#         np.save('../results/'+dataset+'/OurTool/RQ3/table2/R_act_'+str(num_samples)+'_'+str(trial)+'.npy',R_act)\n",
    "#         np.save('../results/'+dataset+'/OurTool/RQ3/table2/R_deact_'+str(num_samples)+'_'+str(trial)+'.npy',R_deact)\n",
    "#         np.save('../results/'+dataset+'/OurTool/RQ3/table2/R_diffR_'+str(num_samples)+'_'+str(trial)+'.npy',diff_R)\n",
    "    \n",
    "    input()\n",
    "    with open('../results/'+dataset+'/OurTool/RQ3/table2/RQ3_table_'+str(num_samples)+'.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['neuron ' + str(i) for i in range(num_neuron)] + ['Biased layer'] + [' Layer influence'])\n",
    "        RQ3_table = np.mean(RQ3_table,axis=0)\n",
    "        writer.writerow(np.append(RQ3_table, [stats.mode(layer_numbers)[0][0], np.mean(layer_influence)], axis=0) )\n",
    "\n",
    "        \n",
    "#     np.save('../results/'+dataset+'/OurTool/RQ3/table2/res_layers_'+str(num_samples)+'.npy',layer_numbers)\n",
    "#     np.save('../results/'+dataset+'/OurTool/RQ3/table2/layer_influence'+str(num_samples)+'.npy',layer_influence)\n",
    "#     np.save('../results/'+dataset+'/OurTool/RQ3/table2/RQ3_table'+str(num_samples)+'.npy',RQ3_table)\n",
    "    print('Time to intervene',time.time() - time1)\n",
    "def main(argv = None):\n",
    "    \n",
    "    dnn_fair_testing(dataset = FLAGS.dataset, \n",
    "                     sens_params = FLAGS.sens_params,\n",
    "                     model_path  = FLAGS.model_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    flags.DEFINE_string(\"dataset\", \"bank\", \"the name of dataset\")\n",
    "    flags.DEFINE_string('model_path', '../models/', 'the path for testing model')\n",
    "    flags.DEFINE_list('sens_params',[1],'sensitive parameters index.1 for age, 9 for gender, 8 for race')\n",
    "    tf.app.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01863354,  0.        , -0.13819876,  0.        ,  0.        ,\n",
       "        0.        , -0.07763975,  0.00465839,  0.        , -0.08229814,\n",
       "        0.        , -0.04347826, -0.07142857, -0.13975155,  0.        ,\n",
       "        0.        , -0.00621118,         nan, -0.01708075, -0.00931677,\n",
       "        0.19565217,  0.        , -0.08695652,  0.        ,  0.        ,\n",
       "       -0.02329193,  0.        ,  0.        , -0.00931677,  0.        ,\n",
       "        0.0015528 , -0.02018634, -0.33567416, -0.10814607, -0.01123596,\n",
       "        0.        , -0.03511236,  0.        ,  0.03792135, -0.21769663,\n",
       "        0.00280899, -0.02247191, -0.01685393,  0.01123596, -0.00842697,\n",
       "        0.00280899, -0.01123596, -0.07303371])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RQ3_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
